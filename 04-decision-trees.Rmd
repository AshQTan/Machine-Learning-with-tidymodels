
# Decision Trees

## Load packages

```{r}

library(rpart)
library(rpart.plot)
library(rio) # painless data import and export
library(tidyverse) # tidyverse packages 
library(tidymodels) # tidymodels framework 
library(here) # reproducible way to find files 
library(glue) # glue strings and objects 
library(patchwork) # arrange ggplots 
library(doParallel) # parallel processing 

theme_set(theme_minimal())

```

## Load data 

Load `train_x_class`, `train_y_class`, `test_x_class`, and `test_y_class` variables we defined in 02-preprocessing.Rmd for this *classification* task. 

```{r}
# Objects: task_reg, task_class
load(here("data", "preprocessed.RData"))
```

## Overview

Decision trees are recursive partitioning methods that divide the predictor spaces into simpler regions and can be visualized in a tree-like structure. They attempt to classify data by dividing it into subsets according to a Y output variable and based on some predictors.  

Let's see how a decision tree classifies if a person suffers from heart disease (`target` = 1) or not (`target` = 0).

## Non-tidy

### Fit model 

```{r}

set.seed(3)

tree <- rpart::rpart(train_y_class ~ ., data = train_x_class,
             # Use method = "anova" for a continuous outcome.
             method = "class",
             
             # Can use "gini" for gini coefficient.
             parms = list(split = "information")) 

# https://stackoverflow.com/questions/4553947/decision-tree-on-information-gain

```

### Investigate 

- Here is the text-based display of the decision tree. Yikes!  :^( 

```{r}

print(tree)

```

Although interpreting the text can be intimidating, a decision tree's main strength is its tree-like plot, which is much easier to interpret.

```{r plot_tree}
rpart.plot::rpart.plot(tree) 
```

We can also look inside of `tree` to see what we can unpack. "variable.importance" is one we should check out! 

```{r}

names(tree)

tree$variable.importance

```
## Tidy models 

### parsnip 

- Build a model 

1. Specify a model 
2. Specify an engine 
3. Specify a mode 

```{r}

# workflow 
tree_wf <- workflow() %>% add_formula(target~.)

# spec 
tree_spec <- decision_tree(
  
           # Mode 
           mode = "classification",
           
           # Tuning parameters
           cost_complexity = NULL, 
           tree_depth = NULL) %>%
  set_engine("rpart") # rpart, c5.0, spark

tree_wf <- tree_wf %>% add_model(tree_spec)

```

- Fit a model

```{r}

tree_fit <- tree_wf %>% fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))

```

### yardstick 

- Let's formally test prediction performance. 

**Metrics**

- `accuracy`: The proportion of the data predicted correctly 

- `precision`: Positive predictive value

- `recall` (specificity): True positive rate (e.g., healthy people really healthy)

![From wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)

- To learn more about other metrics, check out the yardstick package [references](https://yardstick.tidymodels.org/reference/index.html). 

```{r}

# Define performance metrics 
metrics <- yardstick::metric_set(accuracy, precision, recall)

# Build an evaluation function 
evaluate_class <- function(model){
  
  # Bind ground truth and predicted values  
  bind_cols(tibble(truth = test_y_class), # Ground truth 
            predict(model, test_x_class)) %>% # Predicted values 
    
  # Calculate root mean-squared error
  metrics(truth = truth, estimate = .pred_class) 
}

```

```{r}

visualize_metrics <- function(model){
evaluate_class(model) %>%
  ggplot(aes(x = fct_reorder(glue("{toupper(.metric)}"), .estimate), y = .estimate)) +
    geom_col() +
    labs(x = "Metrics",
         y = "Estimate")}

tree_fit_viz_metr <- visualize_metrics(tree_fit)

tree_fit_viz_metr

```
- Visualize the confusion matrix. 

  - The following visualization code draws on [Diego Usai's medium post](https://towardsdatascience.com/modelling-with-tidymodels-and-parsnip-bae2c01c131c).
  
```{r}

visualize_conf_mat <- function(model){
  bind_cols(tibble(truth = test_y_class), # Ground truth 
            predict(model, test_x_class)) %>%
  conf_mat(truth, .pred_class) %>%
  pluck(1) %>% # Select index 
  as_tibble() %>% # Vector -> data.frame 
  ggplot(aes(Prediction, Truth, alpha = n)) +
    geom_tile(show.legend = FALSE) +
    geom_text(aes(label = n), 
              color = "red", 
              alpha = 1, 
              size = 13)
}

tree_fit_viz_mat <- visualize_conf_mat(tree_fit)

tree_fit_viz_mat

```

### tune 

#### tune ingredients 

In decision trees the main hyperparameter (configuration setting) is the **complexity parameter** (CP), but the name is a little counterintuitive; a high CP results in a simple decision tree with few splits, whereas a low CP results in a larger decision tree with many splits.  

The other related hyperparameter is `tree_depth`.

```{r}

tune_spec <- 
  decision_tree(
    cost_complexity = tune(), 
    tree_depth = tune(),
    mode = "classification"
  ) %>%
  set_engine("rpart")

tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = 5) # 2 parameters -> 5*5 = 25 combinations 

tree_grid %>%
  count(tree_depth)

# 10-fold cross-validation

set.seed(1234) # for reproducibility 

tree_folds <- vfold_cv(train_x_class %>% bind_cols(tibble(target = train_y_class)))

```

#### Add these elements to a workflow 

```{r}

# Update workflow 
tree_wf <- tree_wf %>% update_model(tune_spec)

cl <- makeCluster(4)
registerDoParallel(cl)

# Tuning results 
tree_res <- tree_wf %>%
  tune_grid(
    resamples = tree_folds, 
    grid = tree_grid,
    metrics = metrics
  )

```

#### Visualize 

- The following plot draws on the [vignette](https://www.tidymodels.org/start/tuning/) of the tidymodels package. 

```{r}

tree_res %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  # Line + Point plot 
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  # Subplots 
  facet_wrap(~ .metric, 
             scales = "free", 
             nrow = 2) +
  # Log scale x 
  scale_x_log10(labels = scales::label_number()) +
  # Discrete color scale 
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0) +
  labs(x = "Cost complexity",
       col = "Tree depth",
       y = NULL)

```
```{r}
# Optimal parameter
best_tree <- select_best(tree_res, "recall")

# Add the parameter to the workflow 
finalize_tree <- tree_wf %>%
  finalize_workflow(best_tree)
```

```{r}

tree_fit_tuned <- finalize_tree %>% 
  fit(train_x_class %>% bind_cols(tibble(target = train_y_class)))

# Metrics 
(tree_fit_viz_metr + labs(title = "Non-tuned")) / (visualize_metrics(tree_fit_tuned) + labs(title = "Tuned"))

# Confusion matrix 
(tree_fit_viz_mat + labs(title = "Non-tuned")) / (visualize_conf_mat(tree_fit_tuned) + labs(title = "Tuned"))

```

- Visualize variable importance 

```{r}

tree_fit_tuned %>%
  pull_workflow_fit() %>%
  vip::vip()

```


TBD: Challenge 2 