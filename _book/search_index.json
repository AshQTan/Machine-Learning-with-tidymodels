[
["ensembles.html", "Chapter 8 Ensembles 8.1 Load packages 8.2 Load data 8.3 Overview 8.4 Non-tidy 8.5 Challenge 5", " Chapter 8 Ensembles 8.1 Load packages library(SuperLearner) ## Loading required package: nnls ## Super Learner ## Version: 2.0-26 ## Package created on 2019-10-27 library(ck37r) ## Registered S3 method overwritten by &#39;pryr&#39;: ## method from ## print.bytes Rcpp library(vip) ## ## Attaching package: &#39;vip&#39; ## The following object is masked from &#39;package:utils&#39;: ## ## vi library(rio) # painless data import and export library(tidyverse) # tidyverse packages ## ── Attaching packages ──────────────────── ## ✓ ggplot2 3.3.2 ✓ purrr 0.3.4 ## ✓ tibble 3.0.3 ✓ dplyr 1.0.2 ## ✓ tidyr 1.1.2 ✓ stringr 1.4.0 ## ✓ readr 1.3.1 ✓ forcats 0.5.0 ## ── Conflicts ──── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(tidymodels) # tidymodels framework ## ── Attaching packages ──────────────────── ## ✓ broom 0.7.0 ✓ recipes 0.1.13 ## ✓ dials 0.0.9 ✓ rsample 0.0.7 ## ✓ infer 0.5.3 ✓ tune 0.1.1 ## ✓ modeldata 0.0.2 ✓ workflows 0.2.0 ## ✓ parsnip 0.1.3 ✓ yardstick 0.0.7 ## ── Conflicts ─── tidymodels_conflicts() ── ## x scales::discard() masks purrr::discard() ## x dplyr::filter() masks stats::filter() ## x recipes::fixed() masks stringr::fixed() ## x dplyr::lag() masks stats::lag() ## x yardstick::spec() masks readr::spec() ## x recipes::step() masks stats::step() library(here) # reproducible way to find files ## here() starts at /home/jae/Machine-Learning-in-R library(glue) # glue strings and objects ## ## Attaching package: &#39;glue&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## collapse suppressMessages(suppressWarnings(library(glmnet))) theme_set(theme_minimal()) 8.2 Load data Load train_x_class, train_y_class, test_x_class, and test_y_class variables we defined in 02-preprocessing.Rmd for this classification task. # Objects: task_reg, task_class load(here(&quot;data&quot; , &quot;preprocessed.RData&quot;)) 8.3 Overview In the preprocessing, lasso, decision tree, random forest, and boosted tree notebooks you have learned: - Ways to setup your data to plug it into different algorithms - Some common moving parts of different algorithms - How to define control structures and grid searches and why they are important - How to configure hyperparameter settings to improve performance - Why comparing more than one algorithm at once is preferred The “SuperLearner” R package is a method that simplifies ensemble learning by allowing you to simultaneously evaluate the cross-validated performance of multiple algorithms and/or a single algorithm with differently tuned hyperparameters. This is a generally advisable approach to machine learning instead of fitting single algorithms. Let’s see how the four classification algorithms you learned in this workshop (1-lasso, 2-decision tree, 3-random forest, and 4-gradient boosted trees) compare to each other and also to 5-binary logistic regression (glm) and to the 6-mean of Y as a benchmark algorithm, in terms of their cross-validated error! A “wrapper” is a short function that adapts an algorithm for the SuperLearner package. Check out the different algorithm wrappers offered by SuperLearner: 8.3.1 Choose algorithms SuperLearner::listWrappers() ## All prediction algorithm wrappers in SuperLearner: ## [1] &quot;SL.bartMachine&quot; &quot;SL.bayesglm&quot; &quot;SL.biglasso&quot; ## [4] &quot;SL.caret&quot; &quot;SL.caret.rpart&quot; &quot;SL.cforest&quot; ## [7] &quot;SL.earth&quot; &quot;SL.extraTrees&quot; &quot;SL.gam&quot; ## [10] &quot;SL.gbm&quot; &quot;SL.glm&quot; &quot;SL.glm.interaction&quot; ## [13] &quot;SL.glmnet&quot; &quot;SL.ipredbagg&quot; &quot;SL.kernelKnn&quot; ## [16] &quot;SL.knn&quot; &quot;SL.ksvm&quot; &quot;SL.lda&quot; ## [19] &quot;SL.leekasso&quot; &quot;SL.lm&quot; &quot;SL.loess&quot; ## [22] &quot;SL.logreg&quot; &quot;SL.mean&quot; &quot;SL.nnet&quot; ## [25] &quot;SL.nnls&quot; &quot;SL.polymars&quot; &quot;SL.qda&quot; ## [28] &quot;SL.randomForest&quot; &quot;SL.ranger&quot; &quot;SL.ridge&quot; ## [31] &quot;SL.rpart&quot; &quot;SL.rpartPrune&quot; &quot;SL.speedglm&quot; ## [34] &quot;SL.speedlm&quot; &quot;SL.step&quot; &quot;SL.step.forward&quot; ## [37] &quot;SL.step.interaction&quot; &quot;SL.stepAIC&quot; &quot;SL.svm&quot; ## [40] &quot;SL.template&quot; &quot;SL.xgboost&quot; ## ## All screening algorithm wrappers in SuperLearner: ## [1] &quot;All&quot; ## [1] &quot;screen.corP&quot; &quot;screen.corRank&quot; &quot;screen.glmnet&quot; ## [4] &quot;screen.randomForest&quot; &quot;screen.SIS&quot; &quot;screen.template&quot; ## [7] &quot;screen.ttest&quot; &quot;write.screen.template&quot; # Compile the algorithm wrappers to be used. sl_lib &lt;- c(&quot;SL.mean&quot;, &quot;SL.glm&quot;, &quot;SL.glmnet&quot;, &quot;SL.rpart&quot;, &quot;SL.ranger&quot;, &quot;SL.xgboost&quot;) 8.4 Non-tidy 8.4.1 Fit model Fit the ensemble! # This is a seed that is compatible with multicore parallel processing. # See ?set.seed for more information. set.seed(1, &quot;L&#39;Ecuyer-CMRG&quot;) # This will take a few minutes to execute - take a look at the .html file to see the output! cv_sl &lt;- SuperLearner::CV.SuperLearner( Y = as.numeric(as.character(train_y_class)), X = train_x_class, family = binomial(), # For a real analysis we would use V = 10. cvControl = list(V = 5L, stratifyCV = TRUE), SL.library = sl_lib, verbose = FALSE) ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Loading required namespace: ranger ## Loading required namespace: xgboost ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading 8.4.2 Risk Risk is a performance estimate - it’s the average loss, and loss is how far off the prediction was for an individual observation. The lower the risk, the fewer errors the model makes in its prediction. SuperLearner’s default loss metric is squared error \\((y_{actual} - y_{predicted})^2\\), so the risk is the mean-squared error (just like in ordinary least squares regression). View the summary, plot results, and compute the AUC! 8.4.3 Plot the risk # Plot the cross-validated risk estimate. plot(cv_sl) 8.4.4 Compute AUC for all estimators auc_table(cv_sl) ## auc se ci_lower ci_upper p-value ## SL.mean_All 0.5000000 0.06879264 0.3651689 0.6348311 2.552338e-09 ## SL.rpart_All 0.7804972 0.04213879 0.6979067 0.8630877 1.966307e-03 ## SL.xgboost_All 0.8389636 0.02915536 0.7818201 0.8961070 1.529895e-02 ## SL.ranger_All 0.8787443 0.02344681 0.8327894 0.9246992 1.605817e-01 ## SuperLearner 0.8934277 0.02198971 0.8503287 0.9365268 3.482441e-01 ## SL.glmnet_All 0.8993125 0.02102393 0.8581064 0.9405187 4.490455e-01 ## DiscreteSL 0.8993125 0.02102393 0.8581064 0.9405187 4.490455e-01 ## SL.glm_All 0.9020051 0.02085217 0.8611356 0.9428747 5.000000e-01 8.4.5 Plot the ROC curve for the best estimator plot_roc(cv_sl) 8.4.6 Review weight distribution for the SuperLearner print(cvsl_weights(cv_sl), row.names = FALSE) ## # Learner Mean SD Min Max ## 1 glm 0.48741 0.15602 0.26996 0.66418 ## 2 glmnet 0.28295 0.29432 0.00000 0.66948 ## 3 ranger 0.10758 0.15429 0.00000 0.33382 ## 4 rpart 0.06523 0.09437 0.00000 0.23188 ## 5 xgboost 0.04817 0.03899 0.01164 0.09719 ## 6 mean 0.00866 0.00890 0.00000 0.02090 “Discrete SL” is when the SuperLearner chooses the single algorithm with the lowest risk. “SuperLearner” is a weighted average of multiple algorithms, or an “ensemble”. In theory the weighted-average should have a little better performance, although they often tie. In this case we only have a few algorithms so the difference is minor. SuperLearner is currently not available in the tidymodels framework. But you’d like to, you can easily build a parsnip model. Here, I just show a snapshot of the whole process. If you are interested in knowing more about it, please take a look at this vignette of the tidymodels. # Set model set_new_model(&quot;superlearner&quot;) # Set mode set_model_mode(model = &quot;superlearner&quot;, mode = &quot;classification&quot;) # Set model engine set_model_engine( &quot;superlearner&quot;, mode = &quot;classification&quot;, eng = &quot;SuperLearner&quot; ) # Set dependency set_dependency(&quot;superlearner&quot;, eng = &quot;SuperLearner&quot;, pkg = &quot;SuperLearner&quot;) # Show model info show_model_info(&quot;superlearner&quot;) ## Information for `superlearner` ## modes: unknown, classification ## ## engines: ## classification: SuperLearner ## ## no registered arguments. ## ## no registered fit modules. ## ## no registered prediction modules. # Add arguments set_model_arg( model = &quot;superlearner&quot;, eng = &quot;SuperLearner&quot;, parsnip = &quot;cv_control&quot;, original = &quot;cvControl&quot;, func = list(pkg = &quot;SuperLearner&quot;, fun = &quot;CV.SuperLearner&quot;), has_submodel = TRUE # Are you making multiple iterations? ) show_model_info(&quot;superlearner&quot;) ## Information for `superlearner` ## modes: unknown, classification ## ## engines: ## classification: SuperLearner ## ## arguments: ## SuperLearner: ## cv_control --&gt; cvControl ## ## no registered fit modules. ## ## no registered prediction modules. 8.5 Challenge 5 Open Challenge 5 in the “Challenges” folder. A longer tutorial on SuperLearner is available here: (https://github.com/ck37/superlearner-guide) "]
]
